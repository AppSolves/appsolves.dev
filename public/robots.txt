# Security-focused robots.txt
User-agent: *
Disallow: /admin/
Disallow: /private/
Disallow: /.git/
Disallow: /src/
Disallow: /node_modules/

# Allow legitimate crawlers for SEO
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Block aggressive crawlers and scrapers
User-agent: SemrushBot
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: BLEXBot
Disallow: /

User-agent: ia_archiver
Disallow: /

# Block common scraping tools
User-agent: wget
Disallow: /

User-agent: curl
Disallow: /

User-agent: HTTrack
Disallow: /

User-agent: WebZIP
Disallow: /

User-agent: WebCopier
Disallow: /

Sitemap: https://appsolves.dev/sitemap.xml
